{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure where to fetch our training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    " # An S3 Bucket Name\n",
    "data_bucket_name='s3webcamuploader83a65c76f8384092b63d212639122190'\n",
    "\n",
    "# A prefix name inside the S3 bucket containing sub-folders of images (one per label class)\n",
    "dataset_name = 'websummit-live-demo' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "role = get_execution_role()\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: BASE_DIR=/tmp\n",
      "env: S3_DATA_BUCKET_NAME=s3webcamuploader83a65c76f8384092b63d212639122190\n",
      "env: DATASET_NAME=websummit-live-demo\n",
      "env: IM2REC=/home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py\n"
     ]
    }
   ],
   "source": [
    "# Find im2rec in our environment and set up some other vars in our environemnt\n",
    "\n",
    "base_dir='/tmp'\n",
    "\n",
    "%env BASE_DIR=$base_dir\n",
    "%env S3_DATA_BUCKET_NAME = $data_bucket_name\n",
    "%env DATASET_NAME = $dataset_name\n",
    "\n",
    "\n",
    "import sys,os\n",
    "\n",
    "suffix='/mxnet/tools/im2rec.py'\n",
    "im2rec = list(filter( (lambda x: os.path.isfile(x + suffix )), sys.path))[0] + suffix\n",
    "%env IM2REC=$im2rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "+ aws s3 sync s3://s3webcamuploader83a65c76f8384092b63d212639122190/public/websummit-live-demo /tmp/websummit-live-demo --quiet\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Pull our images from S3\n",
    "set -x\n",
    "aws s3 sync s3://$S3_DATA_BUCKET_NAME/public/$DATASET_NAME $BASE_DIR/$DATASET_NAME --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n",
      "Label classes:\n",
      "bottle 0\n",
      "card 1\n",
      "human 2\n",
      "Creating RecordIO files\n",
      "Creating .rec file from /tmp/websummit-live-demo_train.lst in /tmp\n",
      "time: 0.013512134552001953  count: 0\n",
      "Creating .rec file from /tmp/websummit-live-demo_test.lst in /tmp\n",
      "time: 0.0011723041534423828  count: 0\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 380K Jan 30 09:04 websummit-live-demo_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 876K Jan 30 09:04 websummit-live-demo_train.rec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# Use the IM2REC script to convert our images into RecordIO files\n",
    "\n",
    "cd $BASE_DIR\n",
    "\n",
    "# First we need to create two LST files (training and test lists), noting the correct label class for each image\n",
    "# We'll also save the output of the LST files command, since it includes a list of all of our label classes\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.3 --train-ratio=0.7 $DATASET_NAME $DATASET_NAME > ${DATASET_NAME}_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat ${DATASET_NAME}_classes\n",
    "\n",
    "# Then we create RecordIO files from the LST files\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_train.lst $DATASET_NAME\n",
    "python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete: s3://sagemaker-us-west-2-541003905521/ic-transfer-learning/train/websummit-live-demo_train.rec\n",
      "delete: s3://sagemaker-us-west-2-541003905521/ic-transfer-learning/validation/websummit-live-demo_test.rec\n",
      "upload: ../../../tmp/websummit-live-demo_train.rec to s3://sagemaker-us-west-2-541003905521/ic-transfer-learning/train/websummit-live-demo_train.rec\n",
      "upload: ../../../tmp/websummit-live-demo_test.rec to s3://sagemaker-us-west-2-541003905521/ic-transfer-learning/validation/websummit-live-demo_test.rec\n"
     ]
    }
   ],
   "source": [
    "# Upload our train and test RecordIO files to S3 in the bucket that our sagemaker session is using\n",
    "bucket = sess.default_bucket()\n",
    "prefix = 'ic-transfer-learning'\n",
    "\n",
    "s3train_path = 's3://{}/{}/train/'.format(bucket, prefix)\n",
    "s3validation_path = 's3://{}/{}/validation/'.format(bucket, prefix)\n",
    "\n",
    "# Clean up any existing data\n",
    "!aws s3 rm s3://{bucket}/{prefix}/train --recursive\n",
    "!aws s3 rm s3://{bucket}/{prefix}/validation --recursive\n",
    "\n",
    "# Upload the rec files to the train and validation channels\n",
    "!aws s3 cp /tmp/{dataset_name}_train.rec $s3train_path\n",
    "!aws s3 cp /tmp/{dataset_name}_test.rec $s3validation_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring the data for our model training to use\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(\n",
    "    s3train_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "validation_data = sagemaker.session.s3_input(\n",
    "    s3validation_path, \n",
    "    distribution='FullyReplicated', \n",
    "    content_type='application/x-recordio', \n",
    "    s3_data_type='S3Prefix'\n",
    ")\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "image_classifier = sagemaker.estimator.Estimator(\n",
    "    training_image,\n",
    "    role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    output_path=s3_output_location,\n",
    "    sagemaker_session=sess\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'use_pretrained_model': 1,\n",
       " 'image_shape': '3,224,224',\n",
       " 'num_classes': 3,\n",
       " 'num_training_samples': 62,\n",
       " 'epochs': 30,\n",
       " 'learning_rate': 0.001,\n",
       " 'mini_batch_size': 5}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes=! ls -l {base_dir}/{dataset_name} | wc -l\n",
    "num_classes=int(num_classes[0]) - 1\n",
    "\n",
    "num_training_samples=! cat {base_dir}/{dataset_name}_train.lst | wc -l\n",
    "num_training_samples = int(num_training_samples[0])\n",
    "\n",
    "# Learn more about the Sagemaker built-in Image Classifier hyperparameters here: https://docs.aws.amazon.com/sagemaker/latest/dg/IC-Hyperparameter.html\n",
    "\n",
    "# These hyperparameters we won't want to change, as they define things like\n",
    "# the size of the images we'll be sending for input, the number of training classes we have, etc.\n",
    "base_hyperparameters=dict(\n",
    "    use_pretrained_model=1,\n",
    "    image_shape='3,224,224',\n",
    "    num_classes=num_classes,\n",
    "    num_training_samples=num_training_samples,\n",
    ")\n",
    "\n",
    "# These are hyperparameters we may want to tune, as they can affect the model training success:\n",
    "hyperparameters={\n",
    "    **base_hyperparameters, \n",
    "    **dict(\n",
    "        epochs=30,\n",
    "        learning_rate=0.001,\n",
    "        mini_batch_size=5,\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "image_classifier.set_hyperparameters(**hyperparameters)\n",
    "\n",
    "hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (Optional) Perform Hyperparameter Tuning\n",
    "\n",
    "Often, you might not know which values for hyperparameters like `learning_rate` and `mini_batch_size` will yield acceptible results. Traditionally, this meant manually running many training jobs with different hyperparameter values, looking at each trained model's performance, and then picking a winner. \n",
    "\n",
    "This type of manual tuning is _very_ time consuming, so you can automate this process using automatic model tuning with SageMaker. Here's some example code to illustrate how to start one of these jobs using the SageMaker Python SDK."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating hyperparameter tuning job with name: image-classification-190130-0244\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tuner import HyperparameterTuner, IntegerParameter, CategoricalParameter, ContinuousParameter\n",
    "hyperparameter_ranges = {'optimizer': CategoricalParameter(['sgd', 'adam']),\n",
    "                         'learning_rate': ContinuousParameter(0.0001, 0.2),\n",
    "                         'mini_batch_size': IntegerParameter(2, 30),\n",
    "                        }\n",
    "\n",
    "objective_metric_name = 'validation:accuracy'\n",
    "\n",
    "tuner = HyperparameterTuner(image_classifier,\n",
    "                            objective_metric_name,\n",
    "                            hyperparameter_ranges,\n",
    "\n",
    "                            max_jobs=50,\n",
    "                            max_parallel_jobs=3)\n",
    "\n",
    "tuner.fit(inputs=data_channels, logs=True, include_cls_metadata=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the training\n",
    "This will take some time because it's provisioning a new container runtime to train our model, then the actual training happens, then the trained model gets uploaded to S3 and the container is shut down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: image-classification-2019-01-30-09-05-07-056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-30 09:05:07 Starting - Starting the training job...\n",
      "2019-01-30 09:05:08 Starting - Launching requested ML instances......\n",
      "2019-01-30 09:06:08 Starting - Preparing the instances for training......\n",
      "2019-01-30 09:07:29 Downloading - Downloading input data...\n",
      "2019-01-30 09:07:40 Training - Downloading the training image.....\n",
      "\u001b[31mDocker entrypoint called with argument(s): train\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/image_classification/default-input.json: {u'beta_1': 0.9, u'gamma': 0.9, u'beta_2': 0.999, u'optimizer': u'sgd', u'use_pretrained_model': 0, u'eps': 1e-08, u'epochs': 30, u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'image_shape': u'3,224,224', u'precision_dtype': u'float32', u'mini_batch_size': 32, u'weight_decay': 0.0001, u'learning_rate': 0.1, u'momentum': 0}\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'use_pretrained_model': u'1', u'epochs': u'30', u'num_training_samples': u'62', u'image_shape': u'3,224,224', u'mini_batch_size': u'5', u'learning_rate': u'0.001', u'num_classes': u'3'}\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'use_pretrained_model': u'1', u'epochs': u'30', u'num_training_samples': u'62', u'image_shape': u'3,224,224', u'mini_batch_size': u'5', u'learning_rate': u'0.001', u'num_classes': u'3'}\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.001', u'epochs': u'30', u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'precision_dtype': u'float32', u'mini_batch_size': u'5', u'num_classes': u'3', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'62'}\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] Final configuration: {u'optimizer': u'sgd', u'learning_rate': u'0.001', u'epochs': u'30', u'lr_scheduler_factor': 0.1, u'num_layers': 152, u'precision_dtype': u'float32', u'mini_batch_size': u'5', u'num_classes': u'3', u'beta_1': 0.9, u'beta_2': 0.999, u'use_pretrained_model': u'1', u'eps': 1e-08, u'weight_decay': 0.0001, u'momentum': 0, u'image_shape': u'3,224,224', u'gamma': 0.9, u'num_training_samples': u'62'}\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 Using pretrained model for initalizing weights and transfer learning\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 ---- Parameters ----\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] Using pretrained model for initalizing weights and transfer learning\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] ---- Parameters ----\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 num_layers: 152\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] num_layers: 152\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] data type: <type 'numpy.float32'>\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 epochs: 30\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] epochs: 30\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 optimizer: sgd\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] optimizer: sgd\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] momentum: 0.900000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 momentum: 0.900000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 weight_decay: 0.000100\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] weight_decay: 0.000100\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 learning_rate: 0.001000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] learning_rate: 0.001000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 lr_scheduler_step defined without lr_scheduler_factor, will be ignored...\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] lr_scheduler_step defined without lr_scheduler_factor, will be ignored...\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 mini_batch_size: 5\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] mini_batch_size: 5\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 image_shape: 3,224,224\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] image_shape: 3,224,224\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] num_classes: 3\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 num_classes: 3\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 num_training_samples: 62\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] num_training_samples: 62\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 augmentation_type: None\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] augmentation_type: None\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 kv_store: device\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] kv_store: device\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] checkpoint_frequency not set, will store the best model\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 multi_label: 0\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] multi_label: 0\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:53 --------------------\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:53 INFO 139863063271232] --------------------\u001b[0m\n",
      "\u001b[31m[09:08:53] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.657.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:209: Loading symbol saved by previous version v0.8.0. Attempting to upgrade...\u001b[0m\n",
      "\u001b[31m[09:08:53] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.657.0/AL2012/generic-flavor/src/src/nnvm/legacy_json_util.cc:217: Symbol successfully upgraded!\u001b[0m\n",
      "\u001b[31m2019-01-30 09:08:55 Setting number of threads: 7\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:08:55 INFO 139863063271232] Setting number of threads: 7\u001b[0m\n",
      "\n",
      "2019-01-30 09:08:50 Training - Training image download completed. Training in progress.\u001b[31m[09:09:07] /opt/brazil-pkg-cache/packages/MXNetECL/MXNetECL-master.657.0/AL2012/generic-flavor/src/src/operator/nn/./cudnn/./cudnn_algoreg-inl.h:97: Running performance tests to find the best convolution algorithm, this can take a while... (setting env variable MXNET_CUDNN_AUTOTUNE_DEFAULT to 0 to disable)\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:11 Epoch[0] Train-accuracy=0.516667\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:11 INFO 139863063271232] Epoch[0] Train-accuracy=0.516667\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:11 Epoch[0] Time cost=4.136\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:11 INFO 139863063271232] Epoch[0] Time cost=4.136\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:12 Epoch[0] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:12 INFO 139863063271232] Epoch[0] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:12 Storing the best model with validation accuracy: 1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:12 INFO 139863063271232] Storing the best model with validation accuracy: 1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:12 Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:12 INFO 139863063271232] Saved checkpoint to \"/opt/ml/model/image-classification-0001.params\"\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:14 Epoch[1] Train-accuracy=0.916667\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:14 Epoch[1] Time cost=1.686\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:14 INFO 139863063271232] Epoch[1] Train-accuracy=0.916667\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:14 INFO 139863063271232] Epoch[1] Time cost=1.686\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:14 Epoch[1] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:14 INFO 139863063271232] Epoch[1] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:16 Epoch[2] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:16 Epoch[2] Time cost=1.713\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:16 INFO 139863063271232] Epoch[2] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:16 INFO 139863063271232] Epoch[2] Time cost=1.713\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:16 Epoch[2] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:16 INFO 139863063271232] Epoch[2] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:19 Epoch[3] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:19 Epoch[3] Time cost=1.672\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:19 INFO 139863063271232] Epoch[3] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:19 INFO 139863063271232] Epoch[3] Time cost=1.672\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:19 Epoch[3] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:19 INFO 139863063271232] Epoch[3] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:21 Epoch[4] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:21 Epoch[4] Time cost=1.686\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:21 INFO 139863063271232] Epoch[4] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:21 INFO 139863063271232] Epoch[4] Time cost=1.686\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:21 Epoch[4] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:21 INFO 139863063271232] Epoch[4] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:23 Epoch[5] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:23 Epoch[5] Time cost=1.690\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:23 INFO 139863063271232] Epoch[5] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:23 INFO 139863063271232] Epoch[5] Time cost=1.690\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:23 Epoch[5] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:23 INFO 139863063271232] Epoch[5] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:25 Epoch[6] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:25 Epoch[6] Time cost=1.730\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:25 INFO 139863063271232] Epoch[6] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:25 INFO 139863063271232] Epoch[6] Time cost=1.730\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:26 Epoch[6] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:26 INFO 139863063271232] Epoch[6] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:28 Epoch[7] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:28 Epoch[7] Time cost=1.677\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:28 INFO 139863063271232] Epoch[7] Train-accuracy=0.950000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:28 INFO 139863063271232] Epoch[7] Time cost=1.677\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:28 Epoch[7] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:28 INFO 139863063271232] Epoch[7] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:30 Epoch[8] Train-accuracy=0.900000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:30 Epoch[8] Time cost=1.696\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:30 INFO 139863063271232] Epoch[8] Train-accuracy=0.900000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:30 INFO 139863063271232] Epoch[8] Time cost=1.696\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:30 Epoch[8] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:30 INFO 139863063271232] Epoch[8] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:32 Epoch[9] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:32 Epoch[9] Time cost=1.721\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:32 INFO 139863063271232] Epoch[9] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:32 INFO 139863063271232] Epoch[9] Time cost=1.721\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:33 Epoch[9] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:33 INFO 139863063271232] Epoch[9] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:35 Epoch[10] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:35 Epoch[10] Time cost=1.674\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:35 INFO 139863063271232] Epoch[10] Train-accuracy=0.966667\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:35 INFO 139863063271232] Epoch[10] Time cost=1.674\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:35 Epoch[10] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:35 INFO 139863063271232] Epoch[10] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:37 Epoch[11] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:37 Epoch[11] Time cost=1.675\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:37 INFO 139863063271232] Epoch[11] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:37 INFO 139863063271232] Epoch[11] Time cost=1.675\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:37 Epoch[11] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:37 INFO 139863063271232] Epoch[11] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:39 Epoch[12] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:39 Epoch[12] Time cost=1.668\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:39 INFO 139863063271232] Epoch[12] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:39 INFO 139863063271232] Epoch[12] Time cost=1.668\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:39 Epoch[12] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:39 INFO 139863063271232] Epoch[12] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:41 Epoch[13] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:41 INFO 139863063271232] Epoch[13] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:41 Epoch[13] Time cost=1.653\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:41 INFO 139863063271232] Epoch[13] Time cost=1.653\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:42 Epoch[13] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:42 INFO 139863063271232] Epoch[13] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:44 Epoch[14] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:44 Epoch[14] Time cost=1.709\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:44 INFO 139863063271232] Epoch[14] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:44 INFO 139863063271232] Epoch[14] Time cost=1.709\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:44 Epoch[14] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:44 INFO 139863063271232] Epoch[14] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:46 Epoch[15] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:46 Epoch[15] Time cost=1.678\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:46 INFO 139863063271232] Epoch[15] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:46 INFO 139863063271232] Epoch[15] Time cost=1.678\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:46 Epoch[15] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:46 INFO 139863063271232] Epoch[15] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:49 Epoch[16] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:49 Epoch[16] Time cost=1.629\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:49 INFO 139863063271232] Epoch[16] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:49 INFO 139863063271232] Epoch[16] Time cost=1.629\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:49 Epoch[16] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:49 INFO 139863063271232] Epoch[16] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:51 Epoch[17] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:51 INFO 139863063271232] Epoch[17] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:51 Epoch[17] Time cost=1.699\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:51 INFO 139863063271232] Epoch[17] Time cost=1.699\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:51 Epoch[17] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:51 INFO 139863063271232] Epoch[17] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:53 Epoch[18] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:53 INFO 139863063271232] Epoch[18] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:53 Epoch[18] Time cost=1.704\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:53 INFO 139863063271232] Epoch[18] Time cost=1.704\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:53 Epoch[18] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:53 INFO 139863063271232] Epoch[18] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:55 Epoch[19] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:55 Epoch[19] Time cost=1.699\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:55 INFO 139863063271232] Epoch[19] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:55 INFO 139863063271232] Epoch[19] Time cost=1.699\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:56 Epoch[19] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:56 INFO 139863063271232] Epoch[19] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:58 Epoch[20] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:58 Epoch[20] Time cost=1.727\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:58 INFO 139863063271232] Epoch[20] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:58 INFO 139863063271232] Epoch[20] Time cost=1.727\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:09:58 INFO 139863063271232] Epoch[20] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:09:58 Epoch[20] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:00 Epoch[21] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:00 Epoch[21] Time cost=1.716\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:00 INFO 139863063271232] Epoch[21] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:00 INFO 139863063271232] Epoch[21] Time cost=1.716\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:00 Epoch[21] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:00 INFO 139863063271232] Epoch[21] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:02 Epoch[22] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:02 INFO 139863063271232] Epoch[22] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:02 INFO 139863063271232] Epoch[22] Time cost=1.698\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:02 Epoch[22] Time cost=1.698\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:03 Epoch[22] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:03 INFO 139863063271232] Epoch[22] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:05 Epoch[23] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:05 INFO 139863063271232] Epoch[23] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:05 Epoch[23] Time cost=1.663\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:05 INFO 139863063271232] Epoch[23] Time cost=1.663\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:05 Epoch[23] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:05 INFO 139863063271232] Epoch[23] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:07 Epoch[24] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:07 Epoch[24] Time cost=1.719\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:07 INFO 139863063271232] Epoch[24] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:07 INFO 139863063271232] Epoch[24] Time cost=1.719\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:07 Epoch[24] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:07 INFO 139863063271232] Epoch[24] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:09 Epoch[25] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:09 Epoch[25] Time cost=1.676\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:09 INFO 139863063271232] Epoch[25] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:09 INFO 139863063271232] Epoch[25] Time cost=1.676\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:09 Epoch[25] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:09 INFO 139863063271232] Epoch[25] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:12 Epoch[26] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:12 Epoch[26] Time cost=1.686\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:12 INFO 139863063271232] Epoch[26] Train-accuracy=0.983333\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:12 INFO 139863063271232] Epoch[26] Time cost=1.686\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:12 Epoch[26] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:12 INFO 139863063271232] Epoch[26] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:14 Epoch[27] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:14 Epoch[27] Time cost=1.682\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:14 INFO 139863063271232] Epoch[27] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:14 INFO 139863063271232] Epoch[27] Time cost=1.682\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:14 Epoch[27] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:14 INFO 139863063271232] Epoch[27] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:16 Epoch[28] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:16 Epoch[28] Time cost=1.670\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:16 INFO 139863063271232] Epoch[28] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:16 INFO 139863063271232] Epoch[28] Time cost=1.670\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:16 Epoch[28] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:16 INFO 139863063271232] Epoch[28] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:18 Epoch[29] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:18 Epoch[29] Time cost=1.707\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:18 INFO 139863063271232] Epoch[29] Train-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:18 INFO 139863063271232] Epoch[29] Time cost=1.707\u001b[0m\n",
      "\u001b[31m2019-01-30 09:10:19 Epoch[29] Validation-accuracy=1.000000\u001b[0m\n",
      "\u001b[31m[01/30/2019 09:10:19 INFO 139863063271232] Epoch[29] Validation-accuracy=1.000000\u001b[0m\n",
      "\n",
      "2019-01-30 09:10:22 Uploading - Uploading generated training model\n",
      "2019-01-30 09:10:59 Completed - Training job completed\n",
      "Billable seconds: 211\n",
      "\n",
      "\n",
      " Finished training! The model is available for download at: s3://sagemaker-us-west-2-541003905521/ic-transfer-learning/output/image-classification-2019-01-30-09-05-07-056/output/model.tar.gz\n",
      "CPU times: user 700 ms, sys: 22.4 ms, total: 722 ms\n",
      "Wall time: 6min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "image_classifier.fit(inputs=data_channels, logs=True)\n",
    "\n",
    "job = image_classifier.latest_training_job\n",
    "model_path = f\"{base_dir}/{job.name}\"\n",
    "\n",
    "print(f\"\\n\\n Finished training! The model is available for download at: {image_classifier.output_path}/{job.name}/output/model.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating model with name: image-classification-2019-01-30-03-48-39-370\n",
      "INFO:sagemaker:Creating endpoint with name image-classification-2019-01-30-02-14-45-646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------------------------------------------------!CPU times: user 538 ms, sys: 27.9 ms, total: 566 ms\n",
      "Wall time: 9min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Deploying a model to an endpoint takes a few minutes to complete\n",
    "\n",
    "deployed_endpoint = image_classifier.deploy(\n",
    "    initial_instance_count = 1,\n",
    "    instance_type = 'ml.t2.medium'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calling a deployed endpoint from Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def classify_deployed(file_name, classes):\n",
    "    payload = None\n",
    "    with open(file_name, 'rb') as f:\n",
    "        payload = f.read()\n",
    "        payload = bytearray(payload)\n",
    "\n",
    "    deployed_endpoint.content_type = 'application/x-image'\n",
    "    result = json.loads(deployed_endpoint.predict(payload))\n",
    "    best_prob_index = np.argmax(result)\n",
    "    return (classes[best_prob_index], result[best_prob_index])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up\n",
    "\n",
    "When we're done with the endpoint, we can just delete it and the backing instances will be released.  Run the following cell to delete the endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Deleting endpoint with name: image-classification-2019-01-30-02-14-45-646\n"
     ]
    }
   ],
   "source": [
    "deployed_endpoint.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "notice": "Copyright 2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.  Licensed under the Apache License, Version 2.0 (the \"License\"). You may not use this file except in compliance with the License. A copy of the License is located at http://aws.amazon.com/apache2.0/ or in the \"license\" file accompanying this file. This file is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License."
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
